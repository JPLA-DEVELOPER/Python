#Coleta de dados da web de forma automatizada.
#CASOS DE USO: 
#              Monitoração de preços.
#              Monitoração de notícias.
#              Geração de leads.
#              Pesquisa de mercado.


#Crawler: Navega na página web alvo  mapeando todas as páginas, caminhos, links, formulários, recursos para dowload.
#Parsing: Análise sintática da página web, transformando o código HTML em uma representação mais fácil de ser processada.
#Scraper: Extrai os dados da página através de seletores CSS, tags HTML, expressões regulares, XPath ou uma combinação deles. Necessita conhecimento prévio da estrutura da página. 
#Existem métodos para dificultar esse processo(ofuscação: Técnica de embaralhar os dados da página, dificultando ou impossibilitando o processo de webscraping).

#Pagina alvo: Fundamentus.

#Ferramentas: Requests: Realiza a requisição HTTP.
#             BeautifulSoup: Biblioteca que facilita o parsing de páginas HTML.
#             Tabulate: Biblioteca para formatar dados no terminal.


#